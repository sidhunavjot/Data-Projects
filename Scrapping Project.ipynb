{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc905081-1562-4c95-b814-e21eb5be36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data successfully saved to 'amazon_data.csv'\n",
      "\n",
      "Extracted Product Data:\n",
      "                                                 Title    Price  \\\n",
      "0   LG 272 L 3 Star Frost-Free Smart Inverter Comp...  29,990.   \n",
      "1   Samsung 236 L, 3 Star, Convertible, Digital In...  26,990.   \n",
      "2   Whirlpool 184 L 2 Star Direct-Cool Single Door...  11,990.   \n",
      "3   Whirlpool 235 L 2 Star Frost Free Double Door ...  21,990.   \n",
      "4   Haier 165 L, 1 Star, Direct-Cool Single Door R...  11,190.   \n",
      "5   Whirlpool 235 L Frost Free Triple-Door Refrige...  25,600.   \n",
      "6   Whirlpool 192 L 3 Star Vitamagic PRO Frost Fre...  15,990.   \n",
      "7   Samsung 236 L, 3 Star, Convertible, Digital In...  26,990.   \n",
      "8   Samsung 183 L, 4 Star, Digital Inverter, Direc...  16,490.   \n",
      "9   Samsung 183 L, 5 Star, Digital Inverter, Direc...  17,690.   \n",
      "10  Godrej 202 L 5 Star Advanced Inverter, Jumbo V...  18,490.   \n",
      "11  Godrej 180 L 2 Star Advanced Capillary Technol...  12,390.   \n",
      "12  Haier 185 L, 2 Star, Direct-Cool Single Door R...  11,990.   \n",
      "13  Whirlpool 184 L 2 Star Direct-Cool Single Door...  12,990.   \n",
      "14  Samsung 183 L, 4 Star, Digital Inverter, Direc...  15,790.   \n",
      "15  Godrej 180 L 2 Star Advanced Capillary Technol...  12,390.   \n",
      "16  Samsung 215 L, 5 Star, Digital Inverter, Direc...  19,990.   \n",
      "17  Whirlpool 215 L Frost Free Triple-Door Refrige...  24,280.   \n",
      "18  Samsung 183 L, 3 Star, Digital Inverter, Direc...  15,290.   \n",
      "19  Whirlpool 270 L (Gross Capacity 300L) Frost Fr...  28,490.   \n",
      "20  LG 655 L Frost-Free Smart Inverter Double Door...  72,990.   \n",
      "21  Godrej 30L Qube Personal Standard Single door ...   7,999.   \n",
      "\n",
      "                                 Brand  \n",
      "0     63.7D x 55.5W x 168H Centimeters  \n",
      "1   63.7D x 55.5W x 154.5H Centimeters  \n",
      "2   60.5D x 53.5W x 118.8H Centimeters  \n",
      "3   65.5D x 56.4W x 158.7H Centimeters  \n",
      "4     62D x 53.1W x 103.5H Centimeters  \n",
      "5         64D x 56W x 161H Centimeters  \n",
      "6   61.8D x 53.6W x 124.7H Centimeters  \n",
      "7   63.7D x 55.5W x 154.5H Centimeters  \n",
      "8       64D x 54.9W x 130H Centimeters  \n",
      "9     66.5D x 53.6W x 133H Centimeters  \n",
      "10  66.7D x 57.7W x 134.2H Centimeters  \n",
      "11    64.5D x 57.6W x 118H Centimeters  \n",
      "12    57D x 53.3W x 117.3H Centimeters  \n",
      "13  65.1D x 53.5W x 118.8H Centimeters  \n",
      "14      64D x 53.2W x 118H Centimeters  \n",
      "15    64.5D x 57.6W x 118H Centimeters  \n",
      "16  71.6D x 57.8W x 144.5H Centimeters  \n",
      "17        64D x 56W x 161H Centimeters  \n",
      "18      64D x 53.2W x 118H Centimeters  \n",
      "19  71.7D x 60.1W x 187.4H Centimeters  \n",
      "20    73.5D x 91.3W x 179H Centimeters  \n",
      "21         15D x 19W x 18H Centimeters  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ScrappingAmazon:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.HEADERS = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 OPR/115.0.0.0',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'\n",
    "        }\n",
    "        self.URL = \"https://www.amazon.in/s?k=refrigerator&crid=284TJSM5X0E0A&sprefix=refrigerator%2Caps%2C253&ref=nb_sb_noss_2\"\n",
    "        self.soup = None  # Ensure soup is always initialized\n",
    "        self.links_list = []  # Ensure links_list is always initialized\n",
    "\n",
    "    def requestAndConvert(self):\n",
    "        \"\"\"Fetches the main Amazon search page and parses it.\"\"\"\n",
    "        try:\n",
    "            webpage = requests.get(self.URL, headers=self.HEADERS)\n",
    "            if webpage.status_code == 200:\n",
    "                self.soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "                return self.soup\n",
    "            else:\n",
    "                print(f\"Error: Page Not Found (Status Code: {webpage.status_code})\")\n",
    "                self.soup = None\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request Error: {e}\")\n",
    "            self.soup = None\n",
    "            return None\n",
    "\n",
    "    def findElements(self):\n",
    "        \"\"\"Extracts product links from the search page.\"\"\"\n",
    "        if self.soup is None:\n",
    "            print(\"Error: No page content to parse. Ensure `requestAndConvert()` succeeded.\")\n",
    "            return None\n",
    "\n",
    "        self.links = self.soup.find_all(\"a\", attrs={'class': 'a-link-normal s-line-clamp-2 s-link-style a-text-normal'})\n",
    "\n",
    "        if not self.links:\n",
    "            print(\"Error: No product links found.\")\n",
    "            return None\n",
    "\n",
    "        self.links_list = [link.get(\"href\") for link in self.links]\n",
    "        return self.links_list\n",
    "\n",
    "    def reachPages(self):\n",
    "        \"\"\"Visits each product page and extracts details like title, price, and brand.\"\"\"\n",
    "        if not self.links_list:\n",
    "            print(\"Error: No product links available. Ensure `findElements()` was executed successfully.\")\n",
    "            return None\n",
    "\n",
    "        self.d = {\"Title\": [], \"Price\": [], \"Brand\": []}\n",
    "\n",
    "        for link in self.links_list:\n",
    "            try:\n",
    "                item_webpage = requests.get(\"https://www.amazon.in\" + link, headers=self.HEADERS)\n",
    "                if item_webpage.status_code == 200:\n",
    "                    self.Item_soup = BeautifulSoup(item_webpage.content, \"html.parser\")\n",
    "                    self.d['Title'].append(self.get_title())\n",
    "                    self.d['Price'].append(self.get_price())\n",
    "                    self.d['Brand'].append(self.get_brand())\n",
    "                else:\n",
    "                    print(f\"Skipping link due to error (Status Code: {item_webpage.status_code})\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching product page: {e}\")\n",
    "\n",
    "        # **Convert dictionary to DataFrame**\n",
    "        amazon_df = pd.DataFrame.from_dict(self.d)\n",
    "\n",
    "        # **Handle missing values: Remove rows with empty titles**\n",
    "        amazon_df['Title'].replace('', np.nan, inplace=True)\n",
    "        amazon_df.dropna(subset=['Title'], inplace=True)\n",
    "\n",
    "        # **Save data to CSV**\n",
    "        amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)\n",
    "        print(\"\\n✅ Data successfully saved to 'amazon_data.csv'\")\n",
    "\n",
    "        return amazon_df\n",
    "\n",
    "    def get_title(self):\n",
    "        \"\"\"Extracts the product title from the page.\"\"\"\n",
    "        try:\n",
    "            title = self.Item_soup.find(\"span\", attrs={\"id\": 'productTitle'})\n",
    "            return title.text.strip() if title else \"N/A\"\n",
    "        except AttributeError:\n",
    "            return \"N/A\"\n",
    "\n",
    "    def get_price(self):\n",
    "        \"\"\"Extracts the product price from the page.\"\"\"\n",
    "        try:\n",
    "            price = self.Item_soup.find(\"span\", attrs={\"class\": 'a-price-whole'})\n",
    "            return price.text.strip() if price else \"N/A\"\n",
    "        except AttributeError:\n",
    "            return \"N/A\"\n",
    "\n",
    "    def get_brand(self):\n",
    "        \"\"\"Extracts the product brand from the page.\"\"\"\n",
    "        try:\n",
    "            brand = self.Item_soup.find(\"span\", attrs={\"class\": \"a-size-base po-break-word\"})\n",
    "            return brand.text.strip() if brand else \"N/A\"\n",
    "        except AttributeError:\n",
    "            return \"N/A\"\n",
    "\n",
    "# **Execution**\n",
    "obj = ScrappingAmazon()\n",
    "\n",
    "# Step 1: Fetch main page content\n",
    "if obj.requestAndConvert():\n",
    "    # Step 2: Extract product links\n",
    "    if obj.findElements():\n",
    "        # Step 3: Fetch product pages, extract details, and save to CSV\n",
    "        amazon_df = obj.reachPages()\n",
    "        print(\"\\nExtracted Product Data:\\n\", amazon_df) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f84e5-e592-4b63-a579-7dc04b6b0f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
